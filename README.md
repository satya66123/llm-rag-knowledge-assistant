# llm-rag-knowledge-assistant

## ğŸ¤– LLM RAG Knowledge Assistant

A complete **Retrieval-Augmented Generation (RAG)** system built from scratch using Python.

This project supports:
- âœ… Document ingestion from local text files
- âœ… Chunking with overlap
- âœ… Embedding generation using SentenceTransformers
- âœ… Vector similarity search using FAISS
- âœ… Grounded answer generation using OpenAI
- âœ… FastAPI backend API (`/ask`)
- âœ… Streamlit Chat UI with sources and controls

---

## ğŸš€ Features

- **Vector Search (FAISS)**
  - Semantic similarity search over chunk embeddings.

- **Chunk-Based Retrieval**
  - Retrieval works on small chunks (not full documents) for higher relevance.

- **Grounded Answering**
  - The assistant answers using only retrieved context.
  - Returns **sources used** for transparency.

- **Persistence**
  - Saves FAISS index and metadata to disk for faster restarts.

- **FastAPI Backend**
  - `/health` and `/ask` endpoints.

- **Streamlit Chat UI**
  - Chat-style interface with sidebar controls.

---

## ğŸ“‚ Project Structure

```text
llm-rag-knowledge-assistant/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ embeddings.py         # FAISS embedding store
â”‚   â”œâ”€â”€ loader.py             # Load .txt documents
â”‚   â”œâ”€â”€ chunking.py           # Text chunking with overlap
â”‚   â”œâ”€â”€ prompts.py            # Context builder + prompt template
â”‚   â”œâ”€â”€ persistence.py        # Save/load FAISS index + metadata
â”‚   â”œâ”€â”€ llm.py                # OpenAI integration
â”‚   â”œâ”€â”€ rag.py                # RAG orchestration
â”‚   â””â”€â”€ main.py               # FastAPI backend appâš™ï¸ Setup
1) Install dependencies
pip install -r requirements.txt

ğŸ” Environment Variables

This project requires an OpenAI API key.

âœ… Windows PowerShell (temporary session)
$env:OPENAI_API_KEY="your_api_key_here"

â–¶ï¸ Run the Application
1) Start FastAPI backend
uvicorn app.main:app --reload


Backend runs at:

http://127.0.0.1:8000

Swagger docs:

http://127.0.0.1:8000/docs

Health check:

http://127.0.0.1:8000/health

2) Start Streamlit Chat UI (recommended)

In a new terminal:

streamlit run ui_streamlit.py


Streamlit runs at:

http://127.0.0.1:8501

âœ… API Usage
POST /ask

Request Body

{
  "question": "What is RAG?",
  "top_k": 3
}


Response
Returns:

answer

sources (doc_id, chunk_id, source path, chunk text)

ğŸ† Result

You get a complete portfolio-ready RAG assistant:

âœ… Retrieval (FAISS)
âœ… Grounded LLM answering (OpenAI)
âœ… Sources included
âœ… API-ready backend
âœ… Chat UI ready for demo

ğŸ§‘â€ğŸ’» Author

Built using a disciplined production-style engineering approach.

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” free to use, modify, and distribute.
See the [`LICENSE`](LICENSE) file for details.

â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_docs/          # Your knowledge base
â”‚       â”œâ”€â”€ doc1.txt
â”‚       â”œâ”€â”€ doc2.txt
â”‚       â””â”€â”€ doc3.txt
â”‚
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ faiss.index
â”‚   â””â”€â”€ metadata.json
â”‚
â”œâ”€â”€ ui_streamlit.py           # Streamlit Chat UI
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ planner.txt
â””â”€â”€ README.md
âš™ï¸ Setup
1) Install dependencies
pip install -r requirements.txt

ğŸ” Environment Variables

This project requires an OpenAI API key.

âœ… Windows PowerShell (temporary session)
$env:OPENAI_API_KEY="your_api_key_here"

â–¶ï¸ Run the Application
1) Start FastAPI backend
uvicorn app.main:app --reload


Backend runs at:

http://127.0.0.1:8000

Swagger docs:

http://127.0.0.1:8000/docs

Health check:

http://127.0.0.1:8000/health

2) Start Streamlit Chat UI (recommended)

In a new terminal:

streamlit run ui_streamlit.py


Streamlit runs at:

http://127.0.0.1:8501

âœ… API Usage
POST /ask

Request Body

{
  "question": "What is RAG?",
  "top_k": 3
}


Response
Returns:

answer

sources (doc_id, chunk_id, source path, chunk text)

ğŸ† Result

You get a complete portfolio-ready RAG assistant:

âœ… Retrieval (FAISS)
âœ… Grounded LLM answering (OpenAI)
âœ… Sources included
âœ… API-ready backend
âœ… Chat UI ready for demo

ğŸ§‘â€ğŸ’» Author

Built using a disciplined production-style engineering approach.

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” free to use, modify, and distribute.
See the [`LICENSE`](LICENSE) file for details.
